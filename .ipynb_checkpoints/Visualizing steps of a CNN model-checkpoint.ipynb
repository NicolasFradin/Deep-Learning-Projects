{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05880924",
   "metadata": {},
   "source": [
    "# Visualizing steps of a CNN model :\n",
    "\n",
    "The Dogs vs. Cats Dataset :\n",
    "* Need to download data on Kaggle with an account\n",
    "* 25000 grayscale images of AÃ—A pixels each, with 2 classes\n",
    "\n",
    "The VGG16 model :\n",
    "* Included in Keras appliations\n",
    "* Pre-trained on ImageSet dataset\n",
    "* ImageSet is 1.4M labeled images with 1000 classes containing animals...\n",
    "\n",
    "There are two ways to use a pre-trained network : \n",
    "* Feature Extraction -> Use the Convutional Base and changing the dense connected classifier\n",
    "    * Predict features using the Convutional Base Network and then applying a own dense connected Classifier\n",
    "    * Extending the  Convutional Base Network by adding own dense connected Classifier on top and running the whole thing end to end on input data. This allow to use data augmentation \n",
    "* Fine Tuning -> Tune the last Convutional Layers of pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e00d7265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory #utility to convert JPEG to RGB tensors\n",
    "from tensorflow.keras.preprocessing import image\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff495d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/dogs_vs_cats/train\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, pathlib\n",
    "original_dir = pathlib.Path(\"datasets/dogs_vs_cats/train\")\n",
    "print(original_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebf9674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already created\n"
     ]
    }
   ],
   "source": [
    "new_base_dir = pathlib.Path(\"datasets/cats_vs_dogs_small\")\n",
    "\n",
    "try:\n",
    "    #Create a subset folder of the entire image folder from Kaggle\n",
    "    def make_subset(subset_name, start_index, end_index):\n",
    "        for category in (\"cat\", \"dog\"):\n",
    "            dir = new_base_dir / subset_name / category\n",
    "            os.makedirs(dir)\n",
    "            fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "            for fname in fnames:\n",
    "                shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "    make_subset(\"train\", start_index=0, end_index=1000)\n",
    "    make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "    make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "except:\n",
    "    print(\"already created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f49891",
   "metadata": {},
   "source": [
    "# Data Preprocessing a single image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0ca9268",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/dogs_vs_cats/train/cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/r3v9z3b56q95ntj7xklzs59m0000gp/T/ipykernel_82799/1828937542.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_img_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/kh/r3v9z3b56q95ntj7xklzs59m0000gp/T/ipykernel_82799/1828937542.py\u001b[0m in \u001b[0;36mget_img_array\u001b[0;34m(img_path, target_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_img_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     img = image.load_img(\n\u001b[0m\u001b[1;32m      5\u001b[0m         img_path, target_size=target_size)\n\u001b[1;32m      6\u001b[0m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m   \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0m\u001b[1;32m    300\u001b[0m                         target_size=target_size, interpolation=interpolation)\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/dogs_vs_cats/train/cat'"
     ]
    }
   ],
   "source": [
    "img_path = original_dir / \"cat\"/ \"cat_1.jpg\"\n",
    "\n",
    "def get_img_array(img_path, target_size):\n",
    "    img = image.load_img(\n",
    "        img_path, target_size=target_size)\n",
    "    array =image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "img_tensor = get_img_array(img_path, target_size=(180, 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b413d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
