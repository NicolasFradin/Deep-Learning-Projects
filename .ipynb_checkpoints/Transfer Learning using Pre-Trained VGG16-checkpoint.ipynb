{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2409a68f",
   "metadata": {},
   "source": [
    "# Transfer Learning using Pre-Trained VGG16\n",
    "\n",
    "The Dogs vs. Cats Dataset :\n",
    "* Need to download data on Kaggle with an account\n",
    "* 25000 grayscale images of AÃ—A pixels each, with 2 classes\n",
    "\n",
    "The VGG16 model :\n",
    "* Included in Keras appliations\n",
    "* Pre-trained on ImageSet dataset\n",
    "* ImageSet is 1.4M labeled images with 1000 classes containing animals...\n",
    "\n",
    "There are two ways to use a pre-trained network : \n",
    "* Feature Extraction -> Use the Convutional Base and changing the dense connected classifier\n",
    "    * Predict features using the Convutional Base Network and then applying a own dense connected Classifier\n",
    "    * Extending the  Convutional Base Network by adding own dense connected Classifier on top and running the whole thing end to end on input data. This allow to use data augmentation \n",
    "* Fine Tuning -> Tune the last Convutional Layers of pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d30cce29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory #utility to convert JPEG to RGB tensors\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc06d9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/dogs_vs_cats/train\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, pathlib\n",
    "original_dir = pathlib.Path(\"datasets/dogs_vs_cats/train\")\n",
    "print(original_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15b9b4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already created\n"
     ]
    }
   ],
   "source": [
    "new_base_dir = pathlib.Path(\"datasets/cats_vs_dogs_small\")\n",
    "\n",
    "try:\n",
    "    #Create a subset folder of the entire image folder from Kaggle\n",
    "    def make_subset(subset_name, start_index, end_index):\n",
    "        for category in (\"cat\", \"dog\"):\n",
    "            dir = new_base_dir / subset_name / category\n",
    "            os.makedirs(dir)\n",
    "            fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "            for fname in fnames:\n",
    "                shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "    make_subset(\"train\", start_index=0, end_index=1000)\n",
    "    make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "    make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "except:\n",
    "    print(\"already created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64abde79",
   "metadata": {},
   "source": [
    "# Data Preprocessing using Generators :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c213a2",
   "metadata": {},
   "source": [
    "Currently the data sits on folders as JPEG files. So data should be formatted as floatting-point tensors before being fed into the network. The steps are :\n",
    "* Read Pictures files \n",
    "* Decode JPEG content to RGB grids of pixels \n",
    "* Convert these into floating-point tensors\n",
    "* Rescale pixels values.\n",
    "\n",
    "Keras gives utility function to do this automatically : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bb37f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = image_dataset_from_directory(    #train_dataset is a generator\n",
    "    new_base_dir / \"train\",   #target folder\n",
    "    image_size=(180, 180),    #Resizes all images to 180x180\n",
    "    batch_size=32)            #batches sizes\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d83c447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 180, 180, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 180, 180, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 180, 180, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 90, 90, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 90, 90, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 90, 90, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 45, 45, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 45, 45, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 45, 45, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 45, 45, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 22, 22, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Dowloading the pre-training VGG16 model included in Keras\n",
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,         #Include Classifier = False\n",
    "    input_shape=(180, 180, 3))\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6756250f",
   "metadata": {},
   "source": [
    "This is the architecture of the VGG16 model. \n",
    "\n",
    "The final feature map has shape (5, 5, 512). That's the feature on top of which you'll stick a densely connected classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb43886",
   "metadata": {},
   "source": [
    "## Fast feature extraction without data augmentation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3e18beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n"
     ]
    }
   ],
   "source": [
    "#Extract features from pre-trained model for each dataset\n",
    "def get_features_and_labels(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for images, labels in dataset:\n",
    "        preprocessed_images = keras.applications.vgg16.preprocess_input(images) #Trasnform JPEG in Tensor\n",
    "        features = conv_base.predict(preprocessed_images) #predict using VGG16 Convs layers -> shape of (5, 5, 512)\n",
    "        all_features.append(features) \n",
    "        all_labels.append(labels)\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "\n",
    "train_features, train_labels =  get_features_and_labels(train_dataset)\n",
    "val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
    "test_features, test_labels =  get_features_and_labels(test_dataset)\n",
    "\n",
    "print(len(train_features), len(train_labels))\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658333f",
   "metadata": {},
   "source": [
    "We have now samples as tensors of size (5, 5, 512). These tensors have to be flatten to be given in our densely connected classifier : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60c035d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 3s 22ms/step - loss: 37.5444 - accuracy: 0.8839 - val_loss: 19.0603 - val_accuracy: 0.9140\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 5.4625 - accuracy: 0.9706 - val_loss: 14.1748 - val_accuracy: 0.9390\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 3.2541 - accuracy: 0.9779 - val_loss: 7.3304 - val_accuracy: 0.9620\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 2.1150 - accuracy: 0.9862 - val_loss: 4.1617 - val_accuracy: 0.9800\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 1.1589 - accuracy: 0.9917 - val_loss: 4.9560 - val_accuracy: 0.9760\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 1.3276 - accuracy: 0.9949 - val_loss: 5.6205 - val_accuracy: 0.9740\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2254 - accuracy: 0.9965 - val_loss: 5.4358 - val_accuracy: 0.9720\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.4109 - accuracy: 0.9969 - val_loss: 4.1172 - val_accuracy: 0.9800\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.7763 - accuracy: 0.9941 - val_loss: 4.7204 - val_accuracy: 0.9780\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.9175 - val_accuracy: 0.9710\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.5782 - accuracy: 0.9955 - val_loss: 4.5825 - val_accuracy: 0.9750\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.1441 - accuracy: 0.9956 - val_loss: 6.2093 - val_accuracy: 0.9780\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.4407 - accuracy: 0.9958 - val_loss: 5.8886 - val_accuracy: 0.9790\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.1468 - accuracy: 0.9992 - val_loss: 8.9815 - val_accuracy: 0.9710\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.0266 - accuracy: 0.9983 - val_loss: 6.9290 - val_accuracy: 0.9780\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.1621 - accuracy: 0.9985 - val_loss: 5.5931 - val_accuracy: 0.9750\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0647 - accuracy: 0.9992 - val_loss: 4.9795 - val_accuracy: 0.9770\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.1358 - accuracy: 0.9975 - val_loss: 6.4212 - val_accuracy: 0.9770\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.8437 - val_accuracy: 0.9730\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.3571 - accuracy: 0.9994 - val_loss: 5.9656 - val_accuracy: 0.9790\n"
     ]
    }
   ],
   "source": [
    "#Densely Connected Classifier on top (Functional API)\n",
    "inputs = keras.Input(shape=(5, 5, 512))\n",
    "x = layers.Flatten()(inputs) #Flatting features in 1-D Vector\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)  #Regularization\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)  #Probas as output in [0;1]\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "#compliling the model\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "#settings for saving the model\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "      filepath=\"VGG16_feature_extraction.keras\",\n",
    "      save_best_only=True, #Save the model at each epoch if it's better than the previous\n",
    "      monitor=\"val_loss\")\n",
    "]\n",
    "\n",
    "#Training the model classifier\n",
    "history = model.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size = 20,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4deb5e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting accuracy and validation curves\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e4cc4f",
   "metadata": {},
   "source": [
    "Here we can see overfitting despite the dropout layer for regularization. The reason is we didn't use data augmentation methods :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d1a6e",
   "metadata": {},
   "source": [
    "Data augmentation is a regularization technique :\n",
    "    * much slower and more expensive\n",
    "    * Not possible if you don't have GPU.\n",
    "    \n",
    "We will write lines of codes we need without trying to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a01207",
   "metadata": {},
   "source": [
    "## Feature extraction using data augmentation :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba93627",
   "metadata": {},
   "source": [
    "This method is much slower than previous one because each sample goes through the network on each epoch.\n",
    "\n",
    "Before, we absolutely need to freeze the layers weights of the VGG16 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f049f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base  = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False)   #Exclude classifier\n",
    "\n",
    "conv_base.trainable = False   #Freezing weights of layers to prevent being updated during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de64ca41",
   "metadata": {},
   "source": [
    "Because if we don't, there is to much parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0de94a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 26\n",
      "This is the number of trainable weights after freezing the conv base: 0\n"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = True #Without freezing\n",
    "print(\"This is the number of trainable weights \"\n",
    "      \"before freezing the conv base:\", len(conv_base.trainable_weights))\n",
    "\n",
    "conv_base.trainable = False #With freezing\n",
    "print(\"This is the number of trainable weights \"\n",
    "      \"after freezing the conv base:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b9ea2c",
   "metadata": {},
   "source": [
    "Here without freezing, we have 26 Tensors to train :\n",
    "* There is 2 Tensors by Conv Layer -> 1 Weights Tensor + 1 Bias Tensor\n",
    "* VGG16 has 13 Conv layers -> 13*2 = 26 Tensors to train\n",
    "\n",
    "\n",
    "And 0 with freezing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6e7d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation layer settings\n",
    "data_augmentation = keras.Sequential(   \n",
    "    [\n",
    "        RandomFlip(\"horizontal\"),\n",
    "        RandomRotation(0.1),\n",
    "        RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "511b15cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (sequential/random_rotation/rotation_matrix/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/r3v9z3b56q95ntj7xklzs59m0000gp/T/ipykernel_79867/3809531539.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#JPEG to Tensors processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    864\u001b[0m           interpolation=self.interpolation)\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m     output = control_flow_util.smart_cond(training, random_rotated_inputs,\n\u001b[0m\u001b[1;32m    867\u001b[0m                                           lambda: inputs)\n\u001b[1;32m    868\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/control_flow_util.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    112\u001b[0m     return control_flow_ops.cond(\n\u001b[1;32m    113\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0;32m--> 114\u001b[0;31m   return smart_module.smart_cond(\n\u001b[0m\u001b[1;32m    115\u001b[0m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py\u001b[0m in \u001b[0;36mrandom_rotated_inputs\u001b[0;34m()\u001b[0m\n\u001b[1;32m    859\u001b[0m       return transform(\n\u001b[1;32m    860\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m           \u001b[0mget_rotation_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_hd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_wd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m           \u001b[0mfill_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m           \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py\u001b[0m in \u001b[0;36mget_rotation_matrix\u001b[0;34m(angles, image_height, image_width, name)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0my_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_angles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         ],\n\u001b[1;32m    759\u001b[0m         axis=1)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2818\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2819\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2820\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2821\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2866\u001b[0m           \u001b[0;31m# Create a constant if it won't be very big. Otherwise create a fill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2867\u001b[0m           \u001b[0;31m# op to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2868\u001b[0;31m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2869\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2870\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[0;34m(value, shape, dtype, name)\u001b[0m\n\u001b[1;32m   2802\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2803\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2804\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2805\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2806\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[0;32m-> 3051\u001b[0;31m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[1;32m   3052\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   3053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (sequential/random_rotation/rotation_matrix/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = keras.applications.vgg16.preprocess_input(x) #JPEG to Tensors processing\n",
    "x = conv_base(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "#Compiling the model\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model settings\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"VGG16_feature_extraction_with_data_augmentation.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "\n",
    "#Training the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the model\n",
    "test_model = keras.models.load_model(\n",
    "    \"VGG16_feature_extraction_with_data_augmentation.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d28d297",
   "metadata": {},
   "source": [
    "# Fine-Tuning a pre-trained model :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c5b2d6",
   "metadata": {},
   "source": [
    "Fine-Tuning allows us to re-train last layers of a pre-trained model in order to better fit our small dataset. Because deeper features maps encode high level concept in images like Cat nose, eyes... That's why these layers contains less information about the image and more about the class of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c914a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Un-freezing the last 4 layers of the VGG16 architecture\n",
    "conv_base.trainable = True\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c43c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5), #Low LR to keep confidence in pre-trained weights\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"VGG16_fine_tuning.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1433d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of the model\n",
    "model = keras.models.load_model(\"fine_tuning.keras\")\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
